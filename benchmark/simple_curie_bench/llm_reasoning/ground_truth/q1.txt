Commands I ran:

export API keys

python llmonk/generate/gsm8k.py --model_name=gpt-4o-mini --save-dir=/workspace/large_language_monkeys/logs/gsm8k_samples_2

python llmonk/evaluate/math_datasets.py --samples_dir=/workspace/large_language_monkeys/logs/gsm8k_samples_2 --save_dir=/workspace/large_language_monkeys/logs/gsm8k_eval_2 --dset=gsm8k

python llmonk/analyze_coverage.py
- which was generated by LLM, with the following content:

import os
import yaml

def calculate_coverage(eval_dir):
    total_problems = 0
    successfully_solved = 0

    for filename in os.listdir(eval_dir):
        if filename.endswith('.yaml'):
            with open(os.path.join(eval_dir, filename), 'r') as f:
                data = yaml.safe_load(f)
                # Assuming each file contains a list of results with a 'success' field
                if 'success' in data and data['success']:
                    successfully_solved += 1
                total_problems += 1

    coverage = successfully_solved / total_problems if total_problems > 0 else 0
    return coverage

if __name__ == '__main__':
    eval_dir = '/workspace/large_language_monkeys/logs/gsm8k_eval_2'
    coverage = calculate_coverage(eval_dir)
    print(f'Coverage: {coverage:.2%}')


Result:

Coverage: 0.00%