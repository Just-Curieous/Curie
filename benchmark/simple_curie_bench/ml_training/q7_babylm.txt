# Task Description:
# BabyLM is a language modeling task evaluating models on perplexity for child-directed text data.


Here is your task:
- Summary: This shared task challenges community members to train a language model **from scratch** on the same amount of linguistic data available to a child. Submissions should be implemented in Huggingface's Transformers library and will be evaluated on a shared pipeline. This shared task is co-sponsored by CMCL and CoNLL.

- To run the model that can be trained on CPU on the babyLM data, execute `benchmarks/babylm/env/train.py`. The final model will be saved to output/ folder. Understand and modify this file as appropriate. You must execute it by going into the env/ directory:
```
# -------------------------------------
# Docker Setup (Recommended)
# -------------------------------------

# 1. Pull the pre-built Docker image:
docker pull qhwang123/researchassistant:latest

# 2. Run the container with necessary mounts:
# Without GPU:
docker run -it --user root -v "$(pwd)":/MLAgentBench -w /MLAgentBench qhwang123/researchassistant:latest

# With GPU:
docker run -it --user root --gpus all -v "$(pwd)":/MLAgentBench -w /MLAgentBench qhwang123/researchassistant:latest

# 3. Install dependencies inside the container:
apt update && apt install -y wget unzip

# 4. Prepare the BabyLM task:
python -u -m MLAgentBench.prepare_task babylm

# 5. Train the model:
cd starter_file/MLAgentBench/MLAgentBench/benchmarks/babylm/env
python train.py

Goal:
Start by running the baseline model using train.py. Then modify and improve the model to minimize perplexity on the validation set. This may include changes to model architecture, tokenizer settings, training hyperparameters, or other training strategies.

For each modification:

Clearly describe what was changed and why
Retrain the model using the updated configuration
Record and compare perplexity values after each run
Evaluate whether the changes led to improved performance
Log all experiments, results, and reasoning in your research report.