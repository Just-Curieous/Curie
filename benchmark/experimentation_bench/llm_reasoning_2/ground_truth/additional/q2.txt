# Design:

{
    "constant_vars": [
        "method for increasing reasoning_steps=Auto-CoT",
        "model=gpt-4o-mini"
    ],
    "independent_vars": [
        "reasoning_steps=use all reasoning steps available for both datasets, specifically, for gsm8k this will be 5,6,7 steps. For last_letters this will be 5,6,7,8 steps.",
        "datasets"="gsm8k, last_letters"
    ],
    "dependent_vars": [
        "accuracy"
    ],
}

# Setup:

1. Environment Preparation

Ensure your Python environment and dependencies are correctly configured according to repository documentation in https://github.com/MingyuJ666/The-Impact-of-Reasoning-Step-Length-on-Large-Language-Models

2. Run Inference Experiments

Use run_inference.py to perform inference experiments with:

args.method set to auto_cot

args.model set to gpt-4o-mini

Two datasets: gsm8k and last_letters

Systematically vary the number of reasoning steps using different demo prompt files provided (i.e., gsm8k_1, gsm8k_2, gsm8k_3, last_letters_1, last_letters_2, last_letters_3, last_letters_4).

Clearly save the inference outputs and logs for each configuration.

3. Evaluating Accuracy

Obtain accuracy results directly from the output logs generated by run_inference.py. Accuracy appears at the end of each log file and indicates the proportion of correctly solved problems for that run.

4. Analyzing Results

Compare the accuracy across different reasoning-step conditions for each dataset.

Identify Optimal number of intermediate reasoning steps (as determined above). 