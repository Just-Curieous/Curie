# Design:

{
    "constant_vars": [
        "method for increasing reasoning_steps=Auto-CoT",
        "model=gpt-4o-mini",
    ],
    "independent_vars": [
        "datasets"="gsm8k, last_letters",
        "reasoning_steps=use at least 3 reasoning steps for each dataset",
    ],
    "dependent_vars": [
        "accuracy",
    ],
}

# Setup:

1. Environment Preparation

Ensure your Python environment and dependencies are correctly configured according to repository documentation in https://github.com/MingyuJ666/The-Impact-of-Reasoning-Step-Length-on-Large-Language-Models

2. Datasets and Reasoning Steps

Select two datasets for testing: gsm8k (math reasoning) and last_letters (pattern recognition).

Use provided demo files to systematically vary the number of reasoning steps (e.g., gsm8k_1, gsm8k_2, last_letters_3, etc.).

3. Run Experiments

Call run_inference.py using the following parameters:

args.method: auto_cot

args.model: gpt-4o-mini

Execute multiple runs per dataset, incrementally adjusting the reasoning steps through corresponding demo files.

Compare dataset task complexity assessments (simple analysis is fine, even if it is in the conclusion) with optimal reasoning steps.

4. Analyze and Summarize Findings

Summarize for each dataset clearly:

Dataset name

Optimal reasoning steps identified

Task complexity analysis

Discuss insights regarding how task complexity influences the optimal reasoning chain length.