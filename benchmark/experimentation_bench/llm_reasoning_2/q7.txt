How do different methods of expanding reasoning steps (i.e., repeating the question, self-verification, making equations, Think about word) affect the model's accuracy, and are some expansion strategies more effective than others?

Additional details:
- Test this for the gsm8k dataset.
- Use GPT-4o-mini as the model.
- The demo files needed to utilize these strategies/methods is already available in the repo below.
- Feel free to refer to the code here: https://github.com/MingyuJ666/The-Impact-of-Reasoning-Step-Length-on-Large-Language-Models