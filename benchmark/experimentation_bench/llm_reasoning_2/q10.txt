Considering that larger models generally perform better, would it be more cost-effective to use a smaller model with longer reasoning chains or a larger model with fewer steps, if the goal were to achieve the most optimal accuracy?

Additional details:
- Use GPT-4o-mini and GPT-4o as the models.
- Use the gsm8k dataset.
- Use the Auto-CoT method for increasing number of reasoning steps.
- Feel free to refer to the code here: https://github.com/MingyuJ666/The-Impact-of-Reasoning-Step-Length-on-Large-Language-Models