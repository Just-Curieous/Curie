Ground truth:
A reasonable model should achieve a perplexity lower than the baseline, indicating improved language modeling performance on child-directed text data.

Baseline (from current train.py run):

Training Loss: 7.0764
Evaluation Loss: 6.0031
Evaluation Perplexity: 404.66
Evaluation Accuracy: 0.1679 (not relevant for this task)