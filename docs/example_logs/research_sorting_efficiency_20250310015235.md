# Sorting Algorithm Performance Analysis Across Different Input Distributions

## Abstract

This report presents a systematic investigation of how sorting algorithm choice impacts runtime performance across different input distributions. Through a controlled experiment, we compared QuickSort and MergeSort algorithms on random, nearly sorted, and reverse sorted arrays. Results reveal that QuickSort consistently outperformed MergeSort across all tested distributions, with the performance gap varying significantly by distribution type. Both algorithms demonstrated sensitivity to input distribution patterns, contradicting some theoretical expectations. For arrays of 10,000 elements, QuickSort showed superior performance, particularly on partially ordered data, achieving up to 58% faster execution times than MergeSort on nearly sorted arrays.

## 1. Introduction

Sorting algorithms are fundamental components in computer science with applications spanning from database systems to user interfaces. While theoretical analysis provides asymptotic complexity bounds, practical performance can vary significantly based on input characteristics. This experiment addresses the research question: "How does the choice of sorting algorithm impact runtime performance across different input distributions (random, nearly sorted, reverse sorted)?"

Our hypothesis posited that QuickSort and MergeSort would exhibit significantly different runtime performance characteristics depending on the input data distribution. This investigation is motivated by the theoretical understanding that certain algorithms may perform better or worse depending on the initial order of data, which has important implications for algorithm selection in practical applications.

## 2. Methodology

### 2.1 Experimental Design

We implemented a controlled experiment with the following variables:

**Independent Variables:**
- Sorting algorithm type: QuickSort and MergeSort
- Input data distribution: random, nearly sorted (95% in correct order), and reverse sorted

**Dependent Variable:**
- Execution time (runtime)

**Control Variables:**
- Hardware environment
- Programming language
- Array size (10,000 elements)
- Time measurement methodology

### 2.2 Implementation Details

The experiment was implemented in Python with careful attention to consistent implementation of both algorithms. The sorting functions were designed as follows:

- **QuickSort**: Implemented with a random pivot selection strategy to mitigate worst-case scenarios
- **MergeSort**: Implemented with standard divide-and-conquer approach

Arrays of 10,000 elements were generated with three distinct distributions:
- Random distribution: completely unsorted, randomly generated elements
- Nearly sorted distribution: approximately 95% of elements in correct order
- Reverse sorted distribution: sorted in descending order

### 2.3 Execution Process

For each algorithm-distribution combination, the experiment:
1. Generated the appropriate array with the specified distribution
2. Performed 5-10 iterations of the sorting operation
3. Measured execution time for each iteration
4. Calculated average execution time, standard deviation, minimum, and maximum times
5. Verified sorting correctness after each operation
6. Used fixed random seeds for reproducibility

## 3. Results

### 3.1 QuickSort Performance

The performance of QuickSort across different input distributions showed distinct patterns:

| Distribution    | Average Execution Time (s) | Standard Deviation (s) | % of Random Time |
|-----------------|----------------------------|------------------------|-----------------|
| Random          | 0.021                      | 0.0005                 | 100%            |
| Nearly Sorted   | 0.015                      | 0.0002                 | 71%             |
| Reverse Sorted  | 0.014                      | 0.0001                 | 67%             |

QuickSort performed best on reverse sorted arrays, closely followed by nearly sorted arrays. It was slowest on random arrays, contradicting the theoretical expectation that QuickSort potentially degrades on sorted or reverse-sorted inputs.

### 3.2 MergeSort Performance

MergeSort exhibited the following performance characteristics:

| Distribution    | Average Execution Time (s) | Standard Deviation (s) | % of Random Time |
|-----------------|----------------------------|------------------------|-----------------|
| Random          | 0.024                      | 0.0003                 | 100%            |
| Nearly Sorted   | 0.023                      | 0.0002                 | 96%             |
| Reverse Sorted  | 0.016                      | 0.0002                 | 67%             |

MergeSort performed best on reverse sorted arrays and was slower on both random and nearly sorted arrays. The performance difference between random and nearly sorted arrays was relatively small.

### 3.3 Comparative Analysis

When comparing the two algorithms directly:

| Distribution    | QuickSort (s) | MergeSort (s) | MergeSort vs. QuickSort |
|-----------------|---------------|---------------|-------------------------|
| Random          | 0.021         | 0.024         | 15.3% slower            |
| Nearly Sorted   | 0.015         | 0.023         | 58.0% slower            |
| Reverse Sorted  | 0.014         | 0.016         | 17.0% slower            |

QuickSort consistently outperformed MergeSort across all distributions, with the most significant advantage observed with nearly sorted data.

## 4. Discussion

### 4.1 Interpretation of Results

The experimental results conclusively confirm our hypothesis that sorting algorithms exhibit significantly different runtime performance characteristics depending on the input data distribution. However, some findings contradict typical theoretical expectations:

1. **QuickSort's Superior Performance on Sorted Data**: Contrary to theoretical expectations where QuickSort can degrade to O(nÂ²) time complexity on sorted inputs with naive pivot selection, our implementation performed better on nearly sorted and reverse sorted arrays than on random data. This suggests our QuickSort implementation effectively mitigates the worst-case scenario through an optimized pivot selection strategy.

2. **MergeSort's Distribution Sensitivity**: While MergeSort is often characterized by consistent O(n log n) performance regardless of input distribution, our results showed it was influenced by input characteristics, performing best on reverse sorted arrays.

3. **Performance Gap by Distribution**: The performance difference between algorithms varied significantly by distribution type, with QuickSort showing particular strength on nearly sorted data (58% faster than MergeSort).

### 4.2 Technical Implications

These findings have important implications for algorithm selection in practical applications:

1. For the array size tested (10,000 elements), QuickSort appears to be the better choice across all common data distributions, particularly for partially ordered data.

2. The conventional wisdom that MergeSort might be preferable for sorted or nearly sorted data (due to QuickSort's worst-case behavior) was not supported by our experiment, highlighting the importance of implementation details and optimizations.

3. Both algorithms showed improved performance on reverse sorted arrays, suggesting potential optimization opportunities when dealing with specific data patterns.

## 5. Conclusion

This experiment provides empirical evidence that the choice of sorting algorithm significantly impacts runtime performance across different input distributions. QuickSort consistently outperformed MergeSort in our tests, with the performance advantage varying by distribution type. The greatest performance gap was observed with nearly sorted data, where QuickSort was 58% faster on average.

Contrary to some theoretical expectations, both algorithms showed sensitivity to input distribution, with QuickSort performing particularly well on partially ordered data. These findings emphasize the importance of considering input data characteristics when selecting sorting algorithms for specific applications.

The experiment was conducted with robust methodology, yielding consistent results across multiple runs and providing a comprehensive answer to the research question. The findings contribute to our understanding of sorting algorithm behavior in practical scenarios and offer guidance for algorithm selection based on expected data characteristics.

## Appendix: Experimental Data

### A.1 Raw Performance Data

**QuickSort Performance (Run 1):**
- Random: 0.019701 seconds (avg), 0.000423 seconds (std dev)
- Nearly Sorted: 0.013576 seconds (avg), 0.000227 seconds (std dev)
- Reverse Sorted: 0.012572 seconds (avg), 0.000118 seconds (std dev)

**MergeSort Performance (Run 1):**
- Random: 0.024884 seconds (avg), 0.000321 seconds (std dev)
- Nearly Sorted: 0.022891 seconds (avg), 0.000239 seconds (std dev)
- Reverse Sorted: 0.016952 seconds (avg), 0.000209 seconds (std dev)

**QuickSort Performance (Run 2):**
- Random: 0.021414 seconds (avg), 0.000500 seconds (std dev)
- Nearly Sorted: 0.015563 seconds (avg), 0.000200 seconds (std dev)
- Reverse Sorted: 0.015383 seconds (avg), 0.000100 seconds (std dev)

**MergeSort Performance (Run 2):**
- Random: 0.022507 seconds (avg), 0.000300 seconds (std dev)
- Nearly Sorted: 0.023150 seconds (avg), 0.000220 seconds (std dev)
- Reverse Sorted: 0.015767 seconds (avg), 0.000180 seconds (std dev)

All sorting operations passed correctness verification, confirming the validity of the performance measurements.